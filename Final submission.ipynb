{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2e1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "import fasttext\n",
    "import ast\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import copy\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import symspellpy\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03386e91",
   "metadata": {},
   "source": [
    "### Eperiemented few them haven't used all\n",
    "    - just attached them incase if you wanna play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c6efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell correction package tries to retrieve the nearest words which would help reducing the noise\n",
    "spell_correction = symspellpy.SymSpell(max_dictionary_edit_distance=2,count_threshold=4)\n",
    "\n",
    "#Engineer, Engineering, and etc would be back to their root words for matching\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#removing stop words from degree and specialization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#experiementing with spacy lemmas as well\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#stemming\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a37680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(text):\n",
    "    \"\"\"\n",
    "    getting lemma from spacy model\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    if len(text)==0:\n",
    "        return []\n",
    "    return [token.lemma_ for token in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ecfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_porter_lemma(text):\n",
    "    \"\"\"\n",
    "    getting lemma or root from nltk model\n",
    "    \"\"\"\n",
    "    return lemmatizer.lemmatize(\"systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bace199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_nlp(sent_a,sent_b):\n",
    "    \"\"\"\n",
    "    getting similarity between docs form spacy model\n",
    "    \"\"\"\n",
    "    a = nlp(sent_a)\n",
    "    b = nlp(sent_b)\n",
    "    return a.similarity(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688db720",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_data = [\"master of science in\", \"bachelor of science in\", \"master of science\", \"bachelor of science\", \n",
    "                \"bachelors in\", \"bachelor's in\", \"bachelors\", \"masters in\", \"master's in\", \"masters\", \n",
    "                \"bs in\", \"ms in\", \"ms\", \"m.s in\", \"m.s\", \"b.s in\", \"b.s\", \"bs in\", \"bs\", \"bachelor of arts\", \"gpa\", \n",
    "                \"bba\", \"b.b.a\", \"mba\", \"m.b.a\", \"b.a\", \"ba\",\"major in\", \"major\", \"minor in\", \"minor\",\n",
    "                \"concentration in\", \"concentration\", \"master's\", \"masters\", \"bachelor's\", \"bachelors\", \n",
    "                \"n/a\", \"master\", \"bachelor\", \"degree\", \"certificate\"]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c682f0d",
   "metadata": {},
   "source": [
    "#### Cleaning degree data wrt mentor so it can be matched to help topics\n",
    "    - etl operations removing stop words from degree data\n",
    "    - tried get_similarity_nlp as well as it taking more time just worked on exact text match nothing fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffa3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(val):\n",
    "    val = val.strip()\n",
    "    out = []\n",
    "    if val!=\"\":\n",
    "        if val.endswith('.'):\n",
    "            val = val[:-1]\n",
    "        if val == \"n/a\":\n",
    "            val = \"\"\n",
    "        temp = val.split()\n",
    "        while val and val[0] not in string.ascii_letters:\n",
    "            val = val[1:]\n",
    "        while val and val[-1] not in string.ascii_letters:\n",
    "            val = val[:-1]\n",
    "        val = \" \".join(temp)\n",
    "        val = val.lower()\n",
    "        val = val.strip()\n",
    "        val = val.replace(\" w/ \",\" and \")\n",
    "        val = val.replace(\"&\",\"and\")\n",
    "        val = val.replace(\"/\",\" \")\n",
    "        val = val.replace(\"-\",\" \")\n",
    "        val = re.sub('[^A-Z^a-z^0-9^\\s]+','',val)\n",
    "        temp = val.split()\n",
    "        temp = [e.strip() for e in temp]\n",
    "        val = \" \".join(temp)\n",
    "        for d in replace_data:\n",
    "            if val.startswith(d+\" \") or \" \"+d+\" \" in val or val.endswith(\" \"+d):\n",
    "                val = val.replace(d+\" \",\"\")\n",
    "                val = val.strip()\n",
    "                while val and val[0] not in string.ascii_letters:\n",
    "                    val = val[1:]\n",
    "                temp = val.split()\n",
    "                temp = [e.strip() for e in temp]\n",
    "                if len(temp)>1:\n",
    "                    while temp and temp[0] in stop_words:\n",
    "                        temp.pop(0)\n",
    "                    while temp and temp[-1] in stop_words:\n",
    "                        temp.pop()\n",
    "                    val = \" \".join(temp)\n",
    "            val = \" \".join(temp)\n",
    "        while val and val[0] not in string.ascii_letters:\n",
    "            val = val[1:]\n",
    "        while val and val[-1] not in string.ascii_letters:\n",
    "            val = val[:-1]\n",
    "        val = val.strip()\n",
    "        val = val.split()\n",
    "        for v in val:\n",
    "            if v not in stop_words and len(v)>2:\n",
    "                out.append(v)\n",
    "        return out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e6a514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentee_major</th>\n",
       "      <th>mentee_help_topics</th>\n",
       "      <th>mentee_experitse</th>\n",
       "      <th>mentor_major</th>\n",
       "      <th>mentor_help_topics</th>\n",
       "      <th>mentor_experitse</th>\n",
       "      <th>final_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Accounting and Financial Management']</td>\n",
       "      <td>['Life Skills', 'Cover Letter Review', 'Career...</td>\n",
       "      <td>['Accounting']</td>\n",
       "      <td>['Accounting and Financial Management']</td>\n",
       "      <td>['Parenting vs. Career', 'Career / Industry Tr...</td>\n",
       "      <td>['Finance', 'Accounting']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Information Systems Management']</td>\n",
       "      <td>['Working Overseas', 'Life Skills', 'Startups'...</td>\n",
       "      <td>['Food &amp; Restaurants', 'Law', 'Computer - IT S...</td>\n",
       "      <td>['Information Systems Management', 'Project Ma...</td>\n",
       "      <td>['Leadership Skills', 'Working Overseas', 'Per...</td>\n",
       "      <td>['Trade (Wholesale)', 'Government / Public Adm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Cybersecurity Technology', 'Computer Network...</td>\n",
       "      <td>['Leadership Skills', 'Personal and Profession...</td>\n",
       "      <td>['Military &amp; Defense', 'Technology', 'Computer...</td>\n",
       "      <td>['Cybersecurity Technology', 'Computer Network...</td>\n",
       "      <td>['Management', 'Resume / CV Review', 'Career /...</td>\n",
       "      <td>['Government / Public Admin', 'Computer - IT S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Masters of Human Resources Management']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Human Resources']</td>\n",
       "      <td>['Business Administration']</td>\n",
       "      <td>['Leadership Skills', 'Life Skills', 'Intervie...</td>\n",
       "      <td>['Human Resources', 'Advertising / Marketing',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Sociology']</td>\n",
       "      <td>['Leadership Skills', 'Life Skills', 'Manageme...</td>\n",
       "      <td>['Healthcare']</td>\n",
       "      <td>['Business Administration']</td>\n",
       "      <td>['Leadership Skills', 'Working Overseas', 'Per...</td>\n",
       "      <td>['Human Resources', 'Computer - Hardware', 'Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mentee_major  \\\n",
       "0            ['Accounting and Financial Management']   \n",
       "1                 ['Information Systems Management']   \n",
       "2  ['Cybersecurity Technology', 'Computer Network...   \n",
       "3          ['Masters of Human Resources Management']   \n",
       "4                                      ['Sociology']   \n",
       "\n",
       "                                  mentee_help_topics  \\\n",
       "0  ['Life Skills', 'Cover Letter Review', 'Career...   \n",
       "1  ['Working Overseas', 'Life Skills', 'Startups'...   \n",
       "2  ['Leadership Skills', 'Personal and Profession...   \n",
       "3                                                 []   \n",
       "4  ['Leadership Skills', 'Life Skills', 'Manageme...   \n",
       "\n",
       "                                    mentee_experitse  \\\n",
       "0                                     ['Accounting']   \n",
       "1  ['Food & Restaurants', 'Law', 'Computer - IT S...   \n",
       "2  ['Military & Defense', 'Technology', 'Computer...   \n",
       "3                                ['Human Resources']   \n",
       "4                                     ['Healthcare']   \n",
       "\n",
       "                                        mentor_major  \\\n",
       "0            ['Accounting and Financial Management']   \n",
       "1  ['Information Systems Management', 'Project Ma...   \n",
       "2  ['Cybersecurity Technology', 'Computer Network...   \n",
       "3                        ['Business Administration']   \n",
       "4                        ['Business Administration']   \n",
       "\n",
       "                                  mentor_help_topics  \\\n",
       "0  ['Parenting vs. Career', 'Career / Industry Tr...   \n",
       "1  ['Leadership Skills', 'Working Overseas', 'Per...   \n",
       "2  ['Management', 'Resume / CV Review', 'Career /...   \n",
       "3  ['Leadership Skills', 'Life Skills', 'Intervie...   \n",
       "4  ['Leadership Skills', 'Working Overseas', 'Per...   \n",
       "\n",
       "                                    mentor_experitse  final_match  \n",
       "0                          ['Finance', 'Accounting']            1  \n",
       "1  ['Trade (Wholesale)', 'Government / Public Adm...            0  \n",
       "2  ['Government / Public Admin', 'Computer - IT S...            1  \n",
       "3  ['Human Resources', 'Advertising / Marketing',...            0  \n",
       "4  ['Human Resources', 'Computer - Hardware', 'Fi...            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pg_recommendation_data.csv')\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2941640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mentee_major', 'mentee_help_topics', 'mentee_experitse',\n",
       "       'mentor_major', 'mentor_help_topics', 'mentor_experitse',\n",
       "       'final_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea1d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols[:-1]:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7441eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dcc9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols[:-1]:\n",
    "    df[col] = df[col].apply(lambda l:list(itertools.chain.from_iterable([clean_data(x) for x in l])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e50972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df[(df[\"mentee_help_topics\"].str.len()>0) & \n",
    "   ((df[\"mentor_help_topics\"].str.len()>0) | \n",
    "    (df[\"mentor_experitse\"].str.len()>0) | \n",
    "    (df[\"mentor_major\"].str.len()>0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a34633a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32752, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc49af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs,features = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdcb0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = symspellpy.SymSpell(max_dictionary_edit_distance=2,count_threshold=4) #.create_dictionary_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3c705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_words(s,word,verbose=10,dist=2):\n",
    "    out = []\n",
    "    o = s.lookup(word,verbosity=verbose,max_edit_distance=dist)\n",
    "    if len(o)>0:\n",
    "        out = [(t.term,t.count,t.distance) for t in o]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d80bb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_words(s,word,verbose=10,dist=2):\n",
    "    out = []\n",
    "    o = s.lookup(word,verbosity=verbose,max_edit_distance=dist)\n",
    "    if len(o)>0:\n",
    "        out = [(t.term,t.count,t.distance) for t in o]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe24417",
   "metadata": {},
   "source": [
    "#### Helped with fixing typo error from users like systerm and many more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ae25ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spellcheck(s,d):\n",
    "    for key,val in sorted(d.items(),key=lambda x:-x[1]):\n",
    "        if val>10:\n",
    "            s.create_dictionary_entry(key,val)\n",
    "        else:\n",
    "            output = get_nearest_words(s,key)\n",
    "            if len(output)==0:\n",
    "                s.create_dictionary_entry(key,val)\n",
    "            else:\n",
    "                max_count = -1\n",
    "                update_term = None\n",
    "                min_dist = float(\"inf\")\n",
    "                for term,count,dist in output:\n",
    "                    if dist<=min_dist:\n",
    "                        min_dist = dist\n",
    "                        if count>max_count:\n",
    "                            max_count = count\n",
    "                            update_term = term\n",
    "                max_count += val\n",
    "                s.create_dictionary_entry(update_term,max_count)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0aba2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_words_1(s,word,verbose=10,dist=2):\n",
    "    o = s.lookup(word,verbosity=verbose,max_edit_distance=dist)\n",
    "    min_occ = -float(\"inf\")\n",
    "    out = word\n",
    "    distance = float(\"inf\")\n",
    "    for t in o:\n",
    "        if t.count>10 and min_occ<t.count:\n",
    "            min_occ = t.count\n",
    "            out = t.term\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dbd658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-ddb1ab505372>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[col] = df_cleaned[col].apply(lambda x:[get_nearest_words_1(s,w) for w in x])\n"
     ]
    }
   ],
   "source": [
    "s = symspellpy.SymSpell(max_dictionary_edit_distance=2,count_threshold=3) #.create_dictionary_entry()\n",
    "for col in cols[:-1]:\n",
    "    d = Counter(itertools.chain.from_iterable(list(df_cleaned[cols[0]])))\n",
    "    s = create_spellcheck(s,d)\n",
    "    #print(\"done\")\n",
    "    df_cleaned[col] = df_cleaned[col].apply(lambda x:[get_nearest_words_1(s,w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b9b87be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = dict()\n",
    "term_frequency = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d7bbc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols[:-1]:\n",
    "    document_frequency[col] = dict()\n",
    "    term_frequency[col] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2e0a7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols[:-1]:\n",
    "    data = df[col]\n",
    "    i  = 0\n",
    "    for i,vals in enumerate(data):\n",
    "        for v in vals:\n",
    "            if v in document_frequency[col]:\n",
    "                document_frequency[col][v].add(i)\n",
    "            else:\n",
    "                document_frequency[col][v] = set()\n",
    "                document_frequency[col][v].add(i)\n",
    "            if v in term_frequency[col]:\n",
    "                term_frequency[col][v] += 1\n",
    "            else:\n",
    "                term_frequency[col][v] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62250fe",
   "metadata": {},
   "source": [
    "##### used both Tf-idf to give importance wrt word and exact match couldn't find much differnce updated results at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6110435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_logic(mentee_hp,mentor_hp):\n",
    "    mentee_dict = Counter(mentee_hp)\n",
    "    mentor_dict = Counter(mentor_hp)\n",
    "    if len(mentee_hp)==0 or len(mentor_hp)==0:\n",
    "        return 0\n",
    "    score = 0\n",
    "    for key,val in mentee_dict.items():\n",
    "        if key in mentor_dict:\n",
    "            tf = 1\n",
    "            try:\n",
    "                tf = val/term_frequency[\"mentee_help_topics\"].get(key)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(key)\n",
    "            idf = np.log(docs)\n",
    "            try:\n",
    "                idf = np.log(docs/len(document_frequency[\"mentee_help_topics\"].get(key)))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(key)\n",
    "            score = score + (tf*idf)\n",
    "    score = score*1000\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90e5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_vals(a,b):\n",
    "    match = 0\n",
    "    if len(a)==0 or len(b)==0:\n",
    "        return 0\n",
    "    total = len(b)\n",
    "    for word_a in a:\n",
    "        for word_b in b:\n",
    "            if word_a==word_b:\n",
    "                match += 1\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "779733cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mentee_major', 'mentee_help_topics', 'mentee_experitse',\n",
       "       'mentor_major', 'mentor_help_topics', 'mentor_experitse',\n",
       "       'final_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57ccf649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49251779011189367"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_nlp(\"data science\",\"machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990a27d",
   "metadata": {},
   "source": [
    "#### Problems with Spacy and pre-trained vectors:\n",
    "    - They weren't able to help me with similary words are bad, not sure how to choose threshold.\n",
    "    - We need to re-train word2vec embedding wrt our domain might be jobs or degree with description using Skip gram or if we have dictonary we can use it as well would increase confidence a lot which be re-used for future purposes\n",
    "    - you can see the above example as it can't say data science and Machie learnig similiary score should be same, same results were wrt glove and fastext as well slightly better still not that great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78762e25",
   "metadata": {},
   "source": [
    "#### Matching logic:\n",
    "    - Mentee help topic and Mentee expertise are the are he is trying to improve.\n",
    "    - I tried matching the following:\n",
    "        - Mentee help topics with Mentor\n",
    "        - Mentee help topics with Mentor expertise and degree\n",
    "        - Mentee expertise which he is looking gain with Mentor help topic, expertise and degree. \n",
    "        - I gave more importance to help topics and expertise but there wasn't much improvement in results\n",
    "        - I didn't find importance wrt matching Mentee degree wrt other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e04544a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_help_topics\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_help_topics\"],\n",
    "    df[\"mentor_help_topics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df9c4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_ht_expertise\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_help_topics\"],\n",
    "    df[\"mentor_experitse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0af4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_ht_major\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_help_topics\"],\n",
    "    df[\"mentor_major\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca1053f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_expertise_hp\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_experitse\"],\n",
    "    df[\"mentor_help_topics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d63c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_expertise_expertise\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_experitse\"],\n",
    "    df[\"mentor_experitse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa5505de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"match_expertise_major\"] = np.vectorize(match_vals)(\n",
    "    df[\"mentee_experitse\"],\n",
    "    df[\"mentor_major\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3ac9cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mentee_major', 'mentee_help_topics', 'mentee_experitse',\n",
       "       'mentor_major', 'mentor_help_topics', 'mentor_experitse', 'final_match',\n",
       "       'match_help_topics', 'match_ht_expertise', 'match_ht_major',\n",
       "       'match_expertise_hp', 'match_expertise_expertise',\n",
       "       'match_expertise_major'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f94198",
   "metadata": {},
   "source": [
    "###  Tried giving more weight to help topics and expertise match but there isn't much difference\n",
    "    df[\"match_help_topics\"] = df[\"match_help_topics\"]*3\n",
    "    df[\"match_expertise_ht\"] = df[\"match_expertise_ht\"]*2\n",
    "    df[\"match_expertise_expertise\"] = df[\"match_expertise_expertise\"]*3\n",
    "    df[\"match_expertise_hp\"] = df[\"match_expertise_hp\"]*2\n",
    "    df[\"match_expertise_ht\"] = df[\"match_expertise_ht\"]*2\n",
    "        - commented it so you can verify if you feel like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11a111d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentee_major</th>\n",
       "      <th>mentee_help_topics</th>\n",
       "      <th>mentee_experitse</th>\n",
       "      <th>mentor_major</th>\n",
       "      <th>mentor_help_topics</th>\n",
       "      <th>mentor_experitse</th>\n",
       "      <th>final_match</th>\n",
       "      <th>match_help_topics</th>\n",
       "      <th>match_expertise_ht</th>\n",
       "      <th>match_major_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[accounting, financial, management]</td>\n",
       "      <td>[life, skills, cyber, letters, review, career,...</td>\n",
       "      <td>[accounting]</td>\n",
       "      <td>[accounting, financial, management]</td>\n",
       "      <td>[parenting, career, career, industry, trends]</td>\n",
       "      <td>[finance, accounting]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[information, systems, management]</td>\n",
       "      <td>[working, overseas, life, skills, startups, ca...</td>\n",
       "      <td>[food, restaurant, law, computer, services, co...</td>\n",
       "      <td>[information, systems, management, project, ma...</td>\n",
       "      <td>[leadership, skills, working, overseas, person...</td>\n",
       "      <td>[trade, wholesale, government, public, admin, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.898326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cybersecurity, technology, computer, networks...</td>\n",
       "      <td>[leadership, skills, personnel, professional, ...</td>\n",
       "      <td>[military, defense, technology, computer, serv...</td>\n",
       "      <td>[cybersecurity, technology, computer, networks...</td>\n",
       "      <td>[management, resouce, revised, career, industr...</td>\n",
       "      <td>[government, public, admin, computer, services...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[human, resources, management]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[human, resources]</td>\n",
       "      <td>[business, administration]</td>\n",
       "      <td>[leadership, skills, life, skills, interviewin...</td>\n",
       "      <td>[human, resources, advertising, marketing, tel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sociology]</td>\n",
       "      <td>[leadership, skills, life, skills, management,...</td>\n",
       "      <td>[healthcare]</td>\n",
       "      <td>[business, administration]</td>\n",
       "      <td>[leadership, skills, working, overseas, person...</td>\n",
       "      <td>[human, resources, computer, hardware, finance...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.209784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48877</th>\n",
       "      <td>[communications]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[government, public, admin, business, services...</td>\n",
       "      <td>[business, administration]</td>\n",
       "      <td>[leadership, skills, life, skills, management,...</td>\n",
       "      <td>[sports, recreation, education, entertainment,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48878</th>\n",
       "      <td>[business, administration]</td>\n",
       "      <td>[interviewing, tips, web, earth, strategic, re...</td>\n",
       "      <td>[business, services, consulting, transportatio...</td>\n",
       "      <td>[finance]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[international, affairs, development]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48879</th>\n",
       "      <td>[high, school, management, studies, general, s...</td>\n",
       "      <td>[leadership, skills, life, skills, management,...</td>\n",
       "      <td>[non, profit, philanthropy, government, public...</td>\n",
       "      <td>[management, studies]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48880</th>\n",
       "      <td>[environmental, management]</td>\n",
       "      <td>[general, networking, career, exchange, advice...</td>\n",
       "      <td>[environmental, entry]</td>\n",
       "      <td>[environmental, management]</td>\n",
       "      <td>[leadership, skills, working, overseas, life, ...</td>\n",
       "      <td>[entertainment, entry, international, affairs,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48881</th>\n",
       "      <td>[human, resource, management]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[human, resources]</td>\n",
       "      <td>[english, business, administration]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[communications, media, aerospace, defense]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48882 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mentee_major  \\\n",
       "0                    [accounting, financial, management]   \n",
       "1                     [information, systems, management]   \n",
       "2      [cybersecurity, technology, computer, networks...   \n",
       "3                         [human, resources, management]   \n",
       "4                                            [sociology]   \n",
       "...                                                  ...   \n",
       "48877                                   [communications]   \n",
       "48878                         [business, administration]   \n",
       "48879  [high, school, management, studies, general, s...   \n",
       "48880                        [environmental, management]   \n",
       "48881                      [human, resource, management]   \n",
       "\n",
       "                                      mentee_help_topics  \\\n",
       "0      [life, skills, cyber, letters, review, career,...   \n",
       "1      [working, overseas, life, skills, startups, ca...   \n",
       "2      [leadership, skills, personnel, professional, ...   \n",
       "3                                                     []   \n",
       "4      [leadership, skills, life, skills, management,...   \n",
       "...                                                  ...   \n",
       "48877                                                 []   \n",
       "48878  [interviewing, tips, web, earth, strategic, re...   \n",
       "48879  [leadership, skills, life, skills, management,...   \n",
       "48880  [general, networking, career, exchange, advice...   \n",
       "48881                                                 []   \n",
       "\n",
       "                                        mentee_experitse  \\\n",
       "0                                           [accounting]   \n",
       "1      [food, restaurant, law, computer, services, co...   \n",
       "2      [military, defense, technology, computer, serv...   \n",
       "3                                     [human, resources]   \n",
       "4                                           [healthcare]   \n",
       "...                                                  ...   \n",
       "48877  [government, public, admin, business, services...   \n",
       "48878  [business, services, consulting, transportatio...   \n",
       "48879  [non, profit, philanthropy, government, public...   \n",
       "48880                             [environmental, entry]   \n",
       "48881                                 [human, resources]   \n",
       "\n",
       "                                            mentor_major  \\\n",
       "0                    [accounting, financial, management]   \n",
       "1      [information, systems, management, project, ma...   \n",
       "2      [cybersecurity, technology, computer, networks...   \n",
       "3                             [business, administration]   \n",
       "4                             [business, administration]   \n",
       "...                                                  ...   \n",
       "48877                         [business, administration]   \n",
       "48878                                          [finance]   \n",
       "48879                              [management, studies]   \n",
       "48880                        [environmental, management]   \n",
       "48881                [english, business, administration]   \n",
       "\n",
       "                                      mentor_help_topics  \\\n",
       "0          [parenting, career, career, industry, trends]   \n",
       "1      [leadership, skills, working, overseas, person...   \n",
       "2      [management, resouce, revised, career, industr...   \n",
       "3      [leadership, skills, life, skills, interviewin...   \n",
       "4      [leadership, skills, working, overseas, person...   \n",
       "...                                                  ...   \n",
       "48877  [leadership, skills, life, skills, management,...   \n",
       "48878                                                 []   \n",
       "48879                                                 []   \n",
       "48880  [leadership, skills, working, overseas, life, ...   \n",
       "48881                                                 []   \n",
       "\n",
       "                                        mentor_experitse  final_match  \\\n",
       "0                                  [finance, accounting]            1   \n",
       "1      [trade, wholesale, government, public, admin, ...            0   \n",
       "2      [government, public, admin, computer, services...            1   \n",
       "3      [human, resources, advertising, marketing, tel...            0   \n",
       "4      [human, resources, computer, hardware, finance...            0   \n",
       "...                                                  ...          ...   \n",
       "48877  [sports, recreation, education, entertainment,...            0   \n",
       "48878              [international, affairs, development]            1   \n",
       "48879                                                 []            1   \n",
       "48880  [entertainment, entry, international, affairs,...            0   \n",
       "48881        [communications, media, aerospace, defense]            0   \n",
       "\n",
       "       match_help_topics  match_expertise_ht  match_major_ht  \n",
       "0               0.840836                   0               0  \n",
       "1              14.898326                   0               0  \n",
       "2               1.927130                   0               0  \n",
       "3               0.000000                   0               0  \n",
       "4              22.209784                   0               0  \n",
       "...                  ...                 ...             ...  \n",
       "48877           0.000000                   0               0  \n",
       "48878           0.000000                   0               0  \n",
       "48879           0.000000                   0               0  \n",
       "48880           0.840836                   0               0  \n",
       "48881           0.000000                   0               0  \n",
       "\n",
       "[48882 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3469646",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[(df[\"mentee_help_topics\"].str.len()>0 | (df[\"mentee_experitse\"].str.len()>0)) & \n",
    "   (((df[\"mentor_help_topics\"].str.len()>0) ) | (df[\"mentor_experitse\"].str.len()>0)\n",
    "   | (df[\"mentor_major\"].str.len()>0))\n",
    "         ][['match_help_topics', 'match_ht_expertise', 'match_ht_major',\n",
    "       'match_expertise_hp', 'match_expertise_expertise',\n",
    "       'match_expertise_major',\"final_match\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f140f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a380c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = test[[\"match_help_topics\",\"match_expertise_ht\",\"match_major_ht\"]]\n",
    "X = test[['match_help_topics', 'match_ht_expertise', 'match_ht_major',\n",
    "       'match_expertise_hp', 'match_expertise_expertise',\n",
    "       'match_expertise_major']]\n",
    "Y = test[['final_match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd01f11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32382, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "767c1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32416888",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7c22150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "466525fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=logreg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99038313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  56, 2272],\n",
       "       [  50, 4099]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(Y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13b05672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6415006947660954"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnf_matrix[0][0]+cnf_matrix[1][1])/(sum(cnf_matrix[0])+sum(cnf_matrix[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558235d",
   "metadata": {},
   "source": [
    "##### using Tf-Idf accuracy:\n",
    "    0.6363913906273851\n",
    "#### Accuracy with just match:\n",
    "    - without removing noise records\n",
    "        0.5826940779380178\n",
    "    - removing nosie records\n",
    "        0.6415006947660954\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683c0d0",
   "metadata": {},
   "source": [
    "##### Tried stemming and tokenization as well, it wasn't that great, please feel free to make slight modifications wrt code.\n",
    "    - don't try spacy for lemmatization it's time consuming and might exhaust you, explore dusk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b399d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'lg_regression.sav'\n",
    "pickle.dump(logreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa435b9f",
   "metadata": {},
   "source": [
    "#### Tried exact using stemming and lemmatization:\n",
    "    - Results were bad and there isn't any information. There was only difference of less than 1-2% Financial lemma wrt nltk is financi, which really tough to match to any word. Found few more issues like that, so haven't gone with that approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25f570",
   "metadata": {},
   "source": [
    "##### Sorry for the delay. Due to multiple interviews, and few personal things to attend I couldn't finish is asap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dedde",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4879a7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
